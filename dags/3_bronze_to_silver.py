from airflow.decorators import dag, task
from airflow.models import Variable
from datetime import datetime
from pyspark import SparkContext
from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip

@dag(
    start_date=datetime(2024, 1, 1),
    schedule=None,
    catchup=False,
    tags=["sisvan", "silver", "delta"],
)
def bronze_to_silver():

    @task.pyspark(
        conn_id="spark_default",
        config_kwargs={
            "spark.jars.packages": ",".join([
                "io.delta:delta-spark_2.12:3.1.0",
                "org.apache.hadoop:hadoop-aws:3.3.4",
                "com.amazonaws:aws-java-sdk-bundle:1.12.0"
            ]),
            "spark.hadoop.fs.s3a.endpoint": Variable.get("MINIO_ENDPOINT"),
            "spark.hadoop.fs.s3a.access.key": Variable.get("MINIO_ACCESS_KEY"),
            "spark.hadoop.fs.s3a.secret.key": Variable.get("MINIO_SECRET_KEY"),
            "spark.hadoop.fs.s3a.path.style.access": "true",
            "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem",
            "spark.hadoop.fs.s3a.connection.ssl.enabled": "false",
            "spark.sql.extensions": "io.delta.sql.DeltaSparkSessionExtension",
            "spark.sql.catalog.spark_catalog": "org.apache.spark.sql.delta.catalog.DeltaCatalog",
            "spark.sql.catalogImplementation": "hive",
            "hive.metastore.uris": "thrift://hive-metastore:9083",
        },
    )
    def transform_to_silver(spark: SparkSession, sc: SparkContext):
        print("ğŸ”„ Iniciando transformaÃ§Ã£o da camada Bronze para Silver...")

        # Leitura da tabela bronze
        print("ğŸ“¥ Lendo tabela 'bronze.sisvan' do Hive Metastore...")
        df = spark.read.table("bronze.sisvan")
        print("âœ… Dados carregados com sucesso!")
        df.printSchema()
        df.show(5)

        # Mapas de substituiÃ§Ã£o
        raca_cor_map = {
            "5": "Indigena", "3": "Amarela", "X": "Invalido", "1": "Branca",
            "4": "Parda", "2": "Preta", "99": "Sem informacao"
        }
        fase_vida_map = {
            "6": "Adolescente", "3": "Entre 2 anos a 5 anos", "7": "Adulto",
            "4": "Entre 5 anos a 7 anos", "8": "Idoso", "1": "Menor de 6 meses",
            "2": "Entre 6 meses a 2 anos", "5": "Entre 7 anos a 10 anos"
        }
        escolaridade_map = {
            "1": "Creche", "5": "Ensino fundamental 5Âª a 8Âª sÃ©ries", "99": "Sem informaÃ§Ã£o",
            "11": "Ensino mÃ©dio especial", "14": "AlfabetizaÃ§Ã£o para adultos (mobral, etc)",
            "6": "Ensino fundamental completo", "2": "PrÃ©-escola (exceto ca)",
            "10": "Ensino mÃ©dio, mÃ©dio2Âº ciclo (cientÃ­fico,tÃ©cnico e etc)", "15": "Nenhum",
            "9": "Ensino fundamental eja - sÃ©ries iniciais (supletivo 5Âª a 8Âª)",
            "13": "Superior, aperfeiÃ§oamento, especializaÃ§Ã£o, mestrado, doutorado",
            "3": "Classe alfabetizada - ca", "4": "Ensino fundamental 1Âª a 4Âª sÃ©ries",
            "12": "Ensino mÃ©dio eja(supletivo)", "7": "Ensino fundamental especial",
            "8": "Ensino fundamental eja - sÃ©ries iniciais (supletivo 1Âª a 4Âª)"
        }
        sistema_origem_map = {"4": "E-sus ab", "1": "Sisvan web", "2": "Auxilio brasil"}
        povo_comunidade_map = {
            "19": "Seringueiros", "15": "Povos de terreiro", "6": "Comunidades do cerrado",
            "2": "Agroextrativistas", "4": "CaiÃ§aras", "12": "Pescadores artesanais",
            "21": "Outros", "1": "Povos quilombolas", "14": "Povos ciganos",
            "20": "Vazanteiros", "5": "Comunidades de fundo e fecho de pasto", "17": "Retireiros",
            "7": "Extrativistas", "3": "Caatingueiros", "13": "Pomeranos", "10": "Marisqueiros",
            "9": "Geraizeiros", "8": "Faxinalenses", "18": "Ribeirinhos", "11": "Pantaneiros",
            "16": "Quebradeiras de coco-de-babaÃ§u"
        }

        print("ğŸ› ï¸ Aplicando mapeamentos semÃ¢nticos...")
        df2 = (
            df.replace(raca_cor_map, subset=["raca_cor"])
              .replace(fase_vida_map, subset=["fase_vida"])
              .replace(escolaridade_map, subset=["escolaridade"])
              .replace(sistema_origem_map, subset=["sistema_origem"])
              .replace(povo_comunidade_map, subset=["povo_comunidade"])
        )

        print("ğŸ“ Criando schema 'silver' no metastore Hive (caso nÃ£o exista)...")
        spark.sql("CREATE DATABASE IF NOT EXISTS silver LOCATION 's3a://silver'")

        print("ğŸ’¾ Gravando dados em 'silver.sisvan' com particionamento por ano, mÃªs e UF...")
        df2.write \
            .format("delta") \
            .mode("overwrite") \
            .partitionBy("ano", "mes", "sigla_uf") \
            .saveAsTable("silver.sisvan")

        print("âœ… Tabela silver.sisvan criada com sucesso no Hive Metastore!")

    transform_to_silver()

bronze_to_silver()
